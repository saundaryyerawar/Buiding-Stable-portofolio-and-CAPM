{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quandl\n",
    "\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#setting figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "\n",
    "#importing required libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import TensorBoard\n",
    "from fastai.structured import add_datepart\n",
    "\n",
    "#to get stock OHCL data\n",
    "from stocker import Stocker\n",
    "\n",
    "quandl.ApiConfig.api_key = 'VGnWgTpUun-Lz-Aeh3gt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Keras is using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = ['MMM', 'ABT', 'ABBV', 'ABMD', 'ACN', 'ATVI', 'ADBE', 'AMD', 'AAP', 'AES', 'AMG', 'AFL', 'A', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALXN', 'ALGN', 'ALLE', 'AGN', 'ADS', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'ABC', 'AME', 'AMGN', 'APH', 'APC', 'ADI', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'AIV', 'AAPL', 'AMAT', 'APTV', 'ADM', 'ARNC', 'ANET', 'AJG', 'AIZ', 'ATO', 'T', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'BHGE', 'BLL', 'BAC', 'BK', 'BAX', 'BBT', 'BDX', 'BRK.B', 'BBY', 'BIIB', 'BLK', 'HRB', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BHF', 'BMY', 'AVGO', 'BR', 'BF.B', 'CHRW', 'COG', 'CDNS', 'CPB', 'COF', 'CPRI', 'CAH', 'KMX', 'CCL', 'CAT', 'CBOE', 'CBRE', 'CBS', 'CE', 'CELG', 'CNC', 'CNP', 'CTL', 'CERN', 'CF', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'XEC', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CTXS', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'CXO', 'COP', 'ED', 'STZ', 'COO', 'CPRT', 'GLW', 'COST', 'COTY', 'CCI', 'CSX', 'CMI', 'CVS', 'DHI', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'FANG', 'DLR', 'DFS', 'DISCA', 'DISCK', 'DISH', 'DG', 'DLTR', 'D', 'DOV', 'DWDP', 'DTE', 'DRE', 'DUK', 'DXC', 'ETFC', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'EMR', 'ETR', 'EOG', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'EVRG', 'ES', 'RE', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FB', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FE', 'FRC', 'FISV', 'FLT', 'FLIR', 'FLS', 'FLR', 'FMC', 'FL', 'F', 'FTNT', 'FTV', 'FBHS', 'BEN', 'FCX', 'GPS', 'GRMN', 'IT', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GS', 'GWW', 'HAL', 'HBI', 'HOG', 'HRS', 'HIG', 'HAS', 'HCA', 'HCP', 'HP', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HFC', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HPQ', 'HUM', 'HBAN', 'HII', 'IDXX', 'INFO', 'ITW', 'ILMN', 'IR', 'INTC', 'ICE', 'IBM', 'INCY', 'IP', 'IPG', 'IFF', 'INTU', 'ISRG', 'IVZ', 'IPGP', 'IQV', 'IRM', 'JKHY', 'JEC', 'JBHT', 'JEF', 'SJM', 'JNJ', 'JCI', 'JPM', 'JNPR', 'KSU', 'K', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KSS', 'KHC', 'KR', 'LB', 'LLL', 'LH', 'LRCX', 'LW', 'LEG', 'LEN', 'LLY', 'LNC', 'LIN', 'LKQ', 'LMT', 'L', 'LOW', 'LYB', 'MTB', 'MAC', 'M', 'MRO', 'MPC', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MAT', 'MKC', 'MXIM', 'MCD', 'MCK', 'MDT', 'MRK', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MHK', 'TAP', 'MDLZ', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'MYL', 'NDAQ', 'NOV', 'NKTR', 'NTAP', 'NFLX', 'NWL', 'NEM', 'NWSA', 'NWS', 'NEE', 'NLSN', 'NKE', 'NI', 'NBL', 'JWN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'ORLY', 'OXY', 'OMC', 'OKE', 'ORCL', 'PCAR', 'PKG', 'PH', 'PAYX', 'PYPL', 'PNR', 'PBCT', 'PEP', 'PKI', 'PRGO', 'PFE', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'RL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PSA', 'PHM', 'PVH', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RJF', 'RTN', 'O', 'RHT', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'CRM', 'SBAC', 'SLB', 'STX', 'SEE', 'SRE', 'SHW', 'SPG', 'SWKS', 'SLG', 'SNA', 'SO', 'LUV', 'SPGI', 'SWK', 'SBUX', 'STT', 'SYK', 'STI', 'SIVB', 'SYMC', 'SYF', 'SNPS', 'SYY', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'FTI', 'TFX', 'TXN', 'TXT', 'TMO', 'TIF', 'TWTR', 'TJX', 'TMK', 'TSS', 'TSCO', 'TDG', 'TRV', 'TRIP', 'FOXA', 'FOX', 'TSN', 'UDR', 'ULTA', 'USB', 'UAA', 'UA', 'UNP', 'UAL', 'UNH', 'UPS', 'URI', 'UTX', 'UHS', 'UNM', 'VFC', 'VLO', 'VAR', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VIAB', 'V', 'VNO', 'VMC', 'WAB', 'WMT', 'WBA', 'DIS', 'WM', 'WAT', 'WEC', 'WCG', 'WFC', 'WELL', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYNN', 'XEL', 'XRX', 'XLNX', 'XYL', 'YUM', 'ZBH', 'ZION', 'ZTS']\n",
    "best100 = ['msci', 'aig', 'cf', 'dte', 'gww', 're', 'apa', 'ual', 'ndaq', 'amp', 'pru', 'pcar', 'csx', 'dre', 'sna', 'rtn', 'ma', 'usb', 'o', 'hon', 'antm', 'wat', 'tfx', 'akam', 'sti', 'mnst', 'ads', 'dva', 'pep', 'wynn', 'mdlz', 'regn', 'incy', 'pnr', 'etr', 'tss', 'duk', 'mtb', 'ksu', 'fcx', 'aee', 'wfc', 'flir', 'sbac', 'vno', 'mat', 'zion', 'nwl', 'gd', 'amgn', 'mac', 'oxy', 'ed', 'sre', 'blk', 'pld', 'lmt', 'xel', 'gild', 'ctl', 'vlo', 'aes', 'aos', 'arnc', 'eqix', 'cof', 'k', 'es', 'dhr', 'hsy', 'pgr', 'irm', 'udr', 'amzn', 'bk', 'mmc', 'hcp', 'ppl', 'tgt', 'fmc', 'stt', 'ba', 'mcd', 'cme', 'ivz', 'axp', 'intc', 'xom', 'idxx', 'ess', 'amg', 'afl', 'ups', 'mo', 'omc', 'hum', 'swk', 'unm', 'cern', 'ce', 'unp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 years data\n",
    "period = 365 * 10\n",
    "# period of 10 years from 12-31-2017 backwards go back to 01-04-2008\n",
    "date_range = ('01-01-2008', '12-31-2017')\n",
    "max_stocker = '03-27-2018'\n",
    "min_date = datetime.datetime.strptime(date_range[0], \"%m-%d-%Y\")\n",
    "max_date = datetime.datetime.strptime(max_stocker, \"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSCI Stocker Initialized. Data covers 2007-11-15 to 2018-03-27.\n",
      "AIG Stocker Initialized. Data covers 1984-09-07 to 2018-03-27.\n",
      "CF Stocker Initialized. Data covers 2005-08-11 to 2018-03-27.\n",
      "DTE Stocker Initialized. Data covers 1970-01-02 to 2018-03-27.\n",
      "GWW Stocker Initialized. Data covers 1984-12-17 to 2018-03-27.\n",
      "RE Stocker Initialized. Data covers 1995-10-03 to 2018-03-27.\n",
      "APA Stocker Initialized. Data covers 1979-05-15 to 2018-03-27.\n",
      "UAL Stocker Initialized. Data covers 2006-02-06 to 2018-03-27.\n",
      "NDAQ Stocker Initialized. Data covers 2002-07-01 to 2018-03-27.\n",
      "AMP Stocker Initialized. Data covers 2005-09-15 to 2018-03-27.\n",
      "PRU Stocker Initialized. Data covers 2001-12-13 to 2018-03-27.\n",
      "PCAR Stocker Initialized. Data covers 1986-07-09 to 2018-03-27.\n",
      "CSX Stocker Initialized. Data covers 1980-11-03 to 2018-03-27.\n",
      "DRE Stocker Initialized. Data covers 1987-11-05 to 2018-03-27.\n",
      "SNA Stocker Initialized. Data covers 1985-07-01 to 2018-03-27.\n",
      "RTN Stocker Initialized. Data covers 1981-12-31 to 2018-03-27.\n",
      "MA Stocker Initialized. Data covers 2006-05-25 to 2018-03-27.\n",
      "USB Stocker Initialized. Data covers 1987-11-05 to 2018-03-27.\n",
      "O Stocker Initialized. Data covers 1994-10-18 to 2018-03-27.\n",
      "HON Stocker Initialized. Data covers 1970-01-02 to 2018-03-27.\n",
      "ANTM Stocker Initialized. Data covers 2001-10-30 to 2018-03-27.\n",
      "WAT Stocker Initialized. Data covers 1995-11-17 to 2018-03-27.\n",
      "TFX Stocker Initialized. Data covers 1988-02-18 to 2018-03-27.\n",
      "AKAM Stocker Initialized. Data covers 1999-10-29 to 2018-03-27.\n",
      "STI Stocker Initialized. Data covers 1987-12-30 to 2018-03-27.\n",
      "MNST Stocker Initialized. Data covers 1995-08-18 to 2018-03-27.\n",
      "ADS Stocker Initialized. Data covers 2001-06-15 to 2018-03-27.\n",
      "DVA Stocker Initialized. Data covers 1995-10-31 to 2018-03-27.\n",
      "PEP Stocker Initialized. Data covers 1972-06-01 to 2018-03-27.\n",
      "WYNN Stocker Initialized. Data covers 2002-10-25 to 2018-03-27.\n",
      "MDLZ Stocker Initialized. Data covers 2001-06-13 to 2018-03-27.\n",
      "REGN Stocker Initialized. Data covers 1991-04-02 to 2018-03-27.\n",
      "INCY Stocker Initialized. Data covers 1993-11-04 to 2018-03-27.\n",
      "PNR Stocker Initialized. Data covers 1973-05-03 to 2018-03-27.\n",
      "ETR Stocker Initialized. Data covers 1972-06-01 to 2018-03-27.\n",
      "TSS Stocker Initialized. Data covers 1989-06-30 to 2018-03-27.\n",
      "DUK Stocker Initialized. Data covers 1983-04-06 to 2018-03-27.\n",
      "MTB Stocker Initialized. Data covers 1991-10-04 to 2018-03-27.\n",
      "KSU Stocker Initialized. Data covers 1987-11-05 to 2018-03-27.\n",
      "FCX Stocker Initialized. Data covers 1995-07-10 to 2018-03-27.\n",
      "AEE Stocker Initialized. Data covers 1998-01-02 to 2018-03-27.\n",
      "WFC Stocker Initialized. Data covers 1972-06-01 to 2018-03-27.\n",
      "FLIR Stocker Initialized. Data covers 1993-06-22 to 2018-03-27.\n",
      "SBAC Stocker Initialized. Data covers 1999-06-16 to 2018-03-27.\n",
      "VNO Stocker Initialized. Data covers 1988-01-05 to 2018-03-27.\n",
      "MAT Stocker Initialized. Data covers 1982-01-04 to 2018-03-27.\n",
      "ZION Stocker Initialized. Data covers 1990-03-26 to 2018-03-27.\n",
      "NWL Stocker Initialized. Data covers 1984-07-19 to 2018-03-27.\n",
      "GD Stocker Initialized. Data covers 1977-01-03 to 2018-03-27.\n",
      "AMGN Stocker Initialized. Data covers 1984-09-07 to 2018-03-27.\n"
     ]
    }
   ],
   "source": [
    "tickers = best100[:50]\n",
    "tickerobjs = {} \n",
    "for ticker in tickers:\n",
    "    tickerobjs[ticker] = (Stocker(ticker=ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 msci <stocker.Stocker object at 0x7fa72103f470>\n",
      "1 aig <stocker.Stocker object at 0x7fa2d0609b00>\n",
      "2 cf <stocker.Stocker object at 0x7fa2ccacf080>\n",
      "3 dte <stocker.Stocker object at 0x7fa2d8f1ba90>\n",
      "4 gww <stocker.Stocker object at 0x7fa72105a588>\n",
      "5 re <stocker.Stocker object at 0x7fa2d8f57fd0>\n",
      "6 apa <stocker.Stocker object at 0x7fa2d3ff1978>\n",
      "7 ual <stocker.Stocker object at 0x7fa2d89c9a20>\n",
      "8 ndaq <stocker.Stocker object at 0x7fa2ce987c50>\n",
      "9 amp <stocker.Stocker object at 0x7fa2ccae1f28>\n",
      "10 pru <stocker.Stocker object at 0x7fa2d8f3a860>\n",
      "11 pcar <stocker.Stocker object at 0x7fa2ccb28080>\n",
      "12 csx <stocker.Stocker object at 0x7fa2d8954ac8>\n",
      "13 dre <stocker.Stocker object at 0x7fa72105a9e8>\n",
      "14 sna <stocker.Stocker object at 0x7fa2d895ab38>\n",
      "15 rtn <stocker.Stocker object at 0x7fa2d8960a90>\n",
      "16 ma <stocker.Stocker object at 0x7fa72103f080>\n",
      "17 usb <stocker.Stocker object at 0x7fa2cc9112b0>\n",
      "18 o <stocker.Stocker object at 0x7fa2cc9113c8>\n",
      "19 hon <stocker.Stocker object at 0x7fa2cc911390>\n",
      "20 antm <stocker.Stocker object at 0x7fa2d88d0278>\n",
      "21 wat <stocker.Stocker object at 0x7fa2d896bf98>\n",
      "22 tfx <stocker.Stocker object at 0x7fa2d896ba58>\n",
      "23 akam <stocker.Stocker object at 0x7fa2d896b9e8>\n",
      "24 sti <stocker.Stocker object at 0x7fa2cc92bc88>\n",
      "25 mnst <stocker.Stocker object at 0x7fa2cc92b7b8>\n",
      "26 ads <stocker.Stocker object at 0x7fa2d8903630>\n",
      "27 dva <stocker.Stocker object at 0x7fa2d88e5eb8>\n",
      "28 pep <stocker.Stocker object at 0x7fa2d8903c18>\n",
      "29 wynn <stocker.Stocker object at 0x7fa2d8903668>\n",
      "30 mdlz <stocker.Stocker object at 0x7fa721031e10>\n",
      "31 regn <stocker.Stocker object at 0x7fa72103f828>\n",
      "32 incy <stocker.Stocker object at 0x7fa2d8903ef0>\n",
      "33 pnr <stocker.Stocker object at 0x7fa2d88e5550>\n",
      "34 etr <stocker.Stocker object at 0x7fa2d88e59b0>\n",
      "35 tss <stocker.Stocker object at 0x7fa2d88e5240>\n",
      "36 duk <stocker.Stocker object at 0x7fa2d88ed278>\n",
      "37 mtb <stocker.Stocker object at 0x7fa2f2994240>\n",
      "38 ksu <stocker.Stocker object at 0x7fa2ddd146d8>\n",
      "39 fcx <stocker.Stocker object at 0x7fa3057c9e80>\n",
      "40 aee <stocker.Stocker object at 0x7fa306b072e8>\n",
      "41 wfc <stocker.Stocker object at 0x7fa2d89dfe80>\n",
      "42 flir <stocker.Stocker object at 0x7fa2d8aee828>\n",
      "43 sbac <stocker.Stocker object at 0x7fa2ddd82c18>\n",
      "44 vno <stocker.Stocker object at 0x7fa2d70f0828>\n",
      "45 mat <stocker.Stocker object at 0x7fa2e24ccb70>\n",
      "46 zion <stocker.Stocker object at 0x7fa2d8fe8c18>\n",
      "47 nwl <stocker.Stocker object at 0x7fa2d8fe8860>\n",
      "48 gd <stocker.Stocker object at 0x7fa2d8fe8128>\n",
      "49 amgn <stocker.Stocker object at 0x7fa720d44978>\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(tickerobjs.items()): \n",
    "    print(i, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_ciks = pd.read_csv('AllSecTickers.csv')\n",
    "filing_sentiments = {}\n",
    "for ticker in tickers:\n",
    "    cik = int(tickers_ciks.loc[tickers_ciks['ticker'] == ticker]['cik'])\n",
    "    fname = str(cik).zfill(10) + '.csv'\n",
    "    \n",
    "    tenQs = pd.read_csv(\n",
    "        'sentiment-scores/10-Q/{}'.format(fname),\n",
    "        names=['Cik','Coname','Date','Form','Secname','Neg_Score','Neu_Score','Pos_Score']\n",
    "    )\n",
    "\n",
    "    tenKs = pd.read_csv(\n",
    "        'sentiment-scores/10-K/{}'.format(fname),\n",
    "        names=['Cik','Coname','Date','Form','Secname','Neg_Score','Neu_Score','Pos_Score']\n",
    "    )\n",
    "    \n",
    "    sentiments = pd.concat([tenQs, tenKs], ignore_index=True)\n",
    "    sentiments['Date'] = pd.to_datetime(sentiments.Date, format='%Y-%m-%d')\n",
    "    sentiments.index = sentiments['Date']\n",
    "    sentiments = sentiments.sort_index(ascending=True, axis=0)\n",
    "    \n",
    "    filing_sentiments[ticker] = sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only keep stocks within the specified date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "finals = {}\n",
    "for i, (k, v) in enumerate(tickerobjs.items()):\n",
    "    try:\n",
    "        if v.min_date.date() < min_date.date() and v.max_date.date() <= max_date.date():\n",
    "            finals[k] = v\n",
    "    except AttributeError:\n",
    "        pass\n",
    "print(len(finals))\n",
    "tickerobjs = finals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafay/portfolio-risk-assessment-using-ml/stocker.py:172: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  trim_df = df[(df['Date'] >= start_date.date()) &\n",
      "/home/rafay/portfolio-risk-assessment-using-ml/stocker.py:173: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  (df['Date'] <= end_date.date())]\n"
     ]
    }
   ],
   "source": [
    "stocks_data = {}\n",
    "\n",
    "for i, (ticker, stocker) in enumerate(tickerobjs.items()):\n",
    "    df = stocker.make_df(date_range[0], date_range[1])\n",
    "    # ddd date features\n",
    "    add_datepart(df, 'Date', drop=False)\n",
    "    # drop unwanted columns date feature columns\n",
    "    df = df.drop(['Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Elapsed'], axis=1)\n",
    "    df['Is_month_end'] = df['Is_month_end'].astype(int)\n",
    "    df['Is_month_start'] = df['Is_month_start'].astype(int)\n",
    "    # setting index as date\n",
    "    df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "    df.index = df['Date']\n",
    "    # sort df by date\n",
    "    df = df.sort_index(ascending=True, axis=0)\n",
    "    \n",
    "    stocks_data[ticker] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix length issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = pd.date_range(start=date_range[0], end=date_range[1], freq='B')\n",
    "date_df = pd.DataFrame(date_list).rename(columns={0: 'Date'})\n",
    "date_df.index = date_df['Date']\n",
    "date_df.rename(columns={'Date': 'Date2'}, inplace=True)\n",
    "\n",
    "for i, (ticker, df) in enumerate(stocks_data.items()):\n",
    "    stocks_data[ticker] = pd.concat([df, date_df], ignore_index=False, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine sentiments data with DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (ticker, df) in enumerate(stocks_data.items()):\n",
    "    sentiment_df = filing_sentiments[ticker]\n",
    "    forward_merged = pd.merge_asof(df, sentiment_df, left_index=True, right_index=True, direction='backward')\n",
    "    stocks_data[ticker] = forward_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print train, val and test count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2609, 2087, 261, 261)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SPLIT = 0.8  # 80% of total dataset\n",
    "VAL_TEST_SPLIT = 0.5  # 50% of the remaining dataset\n",
    "\n",
    "total_count = len(stocks_data[list(stocks_data.keys())[0]])\n",
    "train_count = int(total_count * TRAIN_SPLIT)\n",
    "left = total_count - train_count\n",
    "valid_count = int(left * VAL_TEST_SPLIT)\n",
    "test_count = int(left - valid_count)\n",
    "\n",
    "print(sum([train_count, valid_count, test_count]))\n",
    "total_count, train_count, valid_count, test_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataset with required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pick_columns = {\n",
    "    'Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume', 'Month', 'Week', 'Day', 'Dayofweek', \n",
    "    'Dayofyear', 'Is_month_end', 'Is_month_start', 'Neg_Score'\n",
    "}\n",
    "y_column = {'Adj. Close'}\n",
    "x_columns = pick_columns - y_column\n",
    "\n",
    "for i, (ticker, df) in enumerate(stocks_data.items()):\n",
    "    # creating new dataframe\n",
    "\n",
    "    new_data = pd.DataFrame(df, columns=pick_columns).interpolate(limit_direction='both')\n",
    "        \n",
    "    x_df = pd.DataFrame(new_data, columns=x_columns)\n",
    "    y_df = pd.DataFrame(new_data, columns=y_column)\n",
    "    stocks_data[ticker] = {\n",
    "        'x': x_df, 'y': y_df,\n",
    "        'x_train': x_df[0:train_count], 'y_train': y_df[0:train_count],\n",
    "        'x_valid': x_df[train_count:train_count+valid_count], 'y_valid': y_df[train_count:train_count+valid_count],\n",
    "        'x_test': x_df[train_count+valid_count:], 'y_test': y_df[train_count+valid_count:],\n",
    "        'new_data': new_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Adj. Volume</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>Week</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Neg_Score</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-04-09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>835100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.925191</td>\n",
       "      <td>28.262311</td>\n",
       "      <td>0.038033</td>\n",
       "      <td>23.712252</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>159500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.993399</td>\n",
       "      <td>28.993399</td>\n",
       "      <td>0.038033</td>\n",
       "      <td>26.521168</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>173800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.934810</td>\n",
       "      <td>27.887148</td>\n",
       "      <td>0.030889</td>\n",
       "      <td>26.097907</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>151000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.742419</td>\n",
       "      <td>27.213778</td>\n",
       "      <td>0.030889</td>\n",
       "      <td>26.367255</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>84500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.848234</td>\n",
       "      <td>27.059865</td>\n",
       "      <td>0.030889</td>\n",
       "      <td>25.741983</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Is_month_end  Adj. Volume  Is_month_start  Dayofyear  Week  \\\n",
       "Date                                                                     \n",
       "2008-04-09           0.0     835100.0             0.0      100.0  15.0   \n",
       "2008-04-10           0.0     159500.0             0.0      101.0  15.0   \n",
       "2008-04-11           0.0     173800.0             0.0      102.0  15.0   \n",
       "2008-04-14           0.0     151000.0             0.0      105.0  16.0   \n",
       "2008-04-15           0.0      84500.0             0.0      106.0  16.0   \n",
       "\n",
       "            Adj. Open  Adj. High  Neg_Score   Adj. Low   Day  Dayofweek  Month  \n",
       "Date                                                                            \n",
       "2008-04-09  26.925191  28.262311   0.038033  23.712252   9.0        2.0    4.0  \n",
       "2008-04-10  28.993399  28.993399   0.038033  26.521168  10.0        3.0    4.0  \n",
       "2008-04-11  26.934810  27.887148   0.030889  26.097907  11.0        4.0    4.0  \n",
       "2008-04-14  26.742419  27.213778   0.030889  26.367255  14.0        0.0    4.0  \n",
       "2008-04-15  26.848234  27.059865   0.030889  25.741983  15.0        1.0    4.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_merged = stocks_data['msci']['x']\n",
    "forward_merged[forward_merged.index >= '2008-04-09'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Train shapes for msci\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for msci\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for msci\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for aig\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for aig\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for aig\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for cf\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for cf\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for cf\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for dte\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for dte\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for dte\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for gww\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for gww\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for gww\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for re\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for re\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for re\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for apa\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for apa\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for apa\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for ual\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for ual\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for ual\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for ndaq\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for ndaq\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for ndaq\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for amp\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for amp\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for amp\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for pru\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for pru\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for pru\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for pcar\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for pcar\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for pcar\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for csx\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for csx\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for csx\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for dre\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for dre\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for dre\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for sna\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for sna\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for sna\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for rtn\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for rtn\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for rtn\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for ma\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for ma\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for ma\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for usb\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for usb\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for usb\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for o\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for o\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for o\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for hon\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for hon\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for hon\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for antm\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for antm\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for antm\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for wat\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for wat\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for wat\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for tfx\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for tfx\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for tfx\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for akam\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for akam\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for akam\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for sti\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for sti\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for sti\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for mnst\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for mnst\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for mnst\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for ads\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for ads\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for ads\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for dva\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for dva\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for dva\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for pep\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for pep\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for pep\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for wynn\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for wynn\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for wynn\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for mdlz\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for mdlz\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for mdlz\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for regn\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for regn\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for regn\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for incy\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for incy\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for incy\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for pnr\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for pnr\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for pnr\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for etr\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for etr\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for etr\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for tss\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for tss\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for tss\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for duk\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for duk\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for duk\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for mtb\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for mtb\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for mtb\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for ksu\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for ksu\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for ksu\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for fcx\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for fcx\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for fcx\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for aee\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for aee\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for aee\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for wfc\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for wfc\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for wfc\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for flir\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for flir\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for flir\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for sbac\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for sbac\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for sbac\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for vno\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for vno\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for vno\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for mat\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for mat\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for mat\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for zion\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for zion\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for zion\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for nwl\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for nwl\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for nwl\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for gd\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for gd\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for gd\n",
      "(261, 12) (261, 1)\n",
      "*****Train shapes for amgn\n",
      "(2087, 12) (2087, 1)\n",
      "*****Validation shapes for amgn\n",
      "(261, 12) (261, 1)\n",
      "*****Test shapes for amgn\n",
      "(261, 12) (261, 1)\n"
     ]
    }
   ],
   "source": [
    "from numpy import hstack\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "for i, (ticker, ds) in enumerate(stocks_data.items()):\n",
    "    x_series = []\n",
    "    y_series = []\n",
    "    x_train_series = []\n",
    "    y_train_series = []\n",
    "    x_valid_series = []\n",
    "    y_valid_series = []\n",
    "    x_test_series = []\n",
    "    y_test_series = []\n",
    "    \n",
    "    ds['x_values'] = ds['x'].values\n",
    "    ds['y_values'] = ds['y'].values\n",
    "    \n",
    "    ds['x_train_values'] = ds['x_train'].values\n",
    "    ds['y_train_values'] = ds['y_train'].values\n",
    "    \n",
    "    ds['x_valid_values'] = ds['x_valid'].values\n",
    "    ds['y_valid_values'] = ds['y_valid'].values\n",
    "    \n",
    "    ds['x_test_values'] = ds['x_test'].values\n",
    "    ds['y_test_values'] = ds['y_test'].values\n",
    "    \n",
    "    # Append values\n",
    "    x_series.append(ds['x_values'])\n",
    "    y_series.append(ds['y_values'])\n",
    "    \n",
    "    x_train_series.append(ds['x_train_values'])\n",
    "    y_train_series.append(ds['y_train_values'])\n",
    "    \n",
    "    x_valid_series.append(ds['x_valid_values'])\n",
    "    y_valid_series.append(ds['y_valid_values'])\n",
    "    \n",
    "    x_test_series.append(ds['x_test_values'])\n",
    "    y_test_series.append(ds['y_test_values'])\n",
    "    \n",
    "\n",
    "    x_dataset = hstack(tuple(x_series))\n",
    "    y_dataset = hstack(tuple(y_series))\n",
    "\n",
    "    x_train_dataset = hstack(tuple(x_train_series))\n",
    "    y_train_dataset = hstack(tuple(y_train_series))\n",
    "\n",
    "    x_valid_dataset = hstack(tuple(x_valid_series))\n",
    "    y_valid_dataset = hstack(tuple(y_valid_series))\n",
    "\n",
    "    x_test_dataset = hstack(tuple(x_test_series))\n",
    "    y_test_dataset = hstack(tuple(y_test_series))\n",
    "\n",
    "    # fit scalers on full series\n",
    "    x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    x_dataset = x_scaler.fit_transform(x_dataset)\n",
    "    y_dataset = y_scaler.fit_transform(y_dataset)\n",
    "    \n",
    "    # Scale train and validation datasets\n",
    "    x_train_dataset = x_scaler.transform(x_train_dataset)\n",
    "    y_train_dataset = y_scaler.transform(y_train_dataset)\n",
    "\n",
    "    x_valid_dataset = x_scaler.transform(x_valid_dataset)\n",
    "    y_valid_dataset = y_scaler.transform(y_valid_dataset)\n",
    "\n",
    "    x_test_dataset = x_scaler.transform(x_test_dataset)\n",
    "    y_test_dataset = y_scaler.transform(y_test_dataset)\n",
    "    \n",
    "    ds['x_train_dataset'] = x_train_dataset\n",
    "    ds['y_train_dataset'] = y_train_dataset\n",
    "    \n",
    "    ds['x_valid_dataset'] = x_valid_dataset\n",
    "    ds['y_valid_dataset'] = y_valid_dataset\n",
    "    \n",
    "    ds['x_test_dataset'] = x_test_dataset\n",
    "    ds['y_test_dataset'] = y_test_dataset\n",
    "    \n",
    "    # Store feature scalers\n",
    "    ds['x_scaler'] = x_scaler\n",
    "    ds['y_scaler'] = y_scaler\n",
    "    \n",
    "    print('*' * 5 + 'Train shapes for ' + ticker)\n",
    "    print(x_train_dataset.shape, y_train_dataset.shape) \n",
    "    \n",
    "    print('*' * 5 + 'Validation shapes for ' + ticker)\n",
    "    print(x_valid_dataset.shape, y_valid_dataset.shape) \n",
    "    \n",
    "    print('*' * 5 + 'Test shapes for ' + ticker)\n",
    "    print(x_test_dataset.shape, y_test_dataset.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples for msci: 111\n",
      "Validation samples for msci: 10\n",
      "Test samples for msci: 10\n",
      "Train samples for aig: 111\n",
      "Validation samples for aig: 10\n",
      "Test samples for aig: 10\n",
      "Train samples for cf: 111\n",
      "Validation samples for cf: 10\n",
      "Test samples for cf: 10\n",
      "Train samples for dte: 111\n",
      "Validation samples for dte: 10\n",
      "Test samples for dte: 10\n",
      "Train samples for gww: 111\n",
      "Validation samples for gww: 10\n",
      "Test samples for gww: 10\n",
      "Train samples for re: 111\n",
      "Validation samples for re: 10\n",
      "Test samples for re: 10\n",
      "Train samples for apa: 111\n",
      "Validation samples for apa: 10\n",
      "Test samples for apa: 10\n",
      "Train samples for ual: 111\n",
      "Validation samples for ual: 10\n",
      "Test samples for ual: 10\n",
      "Train samples for ndaq: 111\n",
      "Validation samples for ndaq: 10\n",
      "Test samples for ndaq: 10\n",
      "Train samples for amp: 111\n",
      "Validation samples for amp: 10\n",
      "Test samples for amp: 10\n",
      "Train samples for pru: 111\n",
      "Validation samples for pru: 10\n",
      "Test samples for pru: 10\n",
      "Train samples for pcar: 111\n",
      "Validation samples for pcar: 10\n",
      "Test samples for pcar: 10\n",
      "Train samples for csx: 111\n",
      "Validation samples for csx: 10\n",
      "Test samples for csx: 10\n",
      "Train samples for dre: 111\n",
      "Validation samples for dre: 10\n",
      "Test samples for dre: 10\n",
      "Train samples for sna: 111\n",
      "Validation samples for sna: 10\n",
      "Test samples for sna: 10\n",
      "Train samples for rtn: 111\n",
      "Validation samples for rtn: 10\n",
      "Test samples for rtn: 10\n",
      "Train samples for ma: 111\n",
      "Validation samples for ma: 10\n",
      "Test samples for ma: 10\n",
      "Train samples for usb: 111\n",
      "Validation samples for usb: 10\n",
      "Test samples for usb: 10\n",
      "Train samples for o: 111\n",
      "Validation samples for o: 10\n",
      "Test samples for o: 10\n",
      "Train samples for hon: 111\n",
      "Validation samples for hon: 10\n",
      "Test samples for hon: 10\n",
      "Train samples for antm: 111\n",
      "Validation samples for antm: 10\n",
      "Test samples for antm: 10\n",
      "Train samples for wat: 111\n",
      "Validation samples for wat: 10\n",
      "Test samples for wat: 10\n",
      "Train samples for tfx: 111\n",
      "Validation samples for tfx: 10\n",
      "Test samples for tfx: 10\n",
      "Train samples for akam: 111\n",
      "Validation samples for akam: 10\n",
      "Test samples for akam: 10\n",
      "Train samples for sti: 111\n",
      "Validation samples for sti: 10\n",
      "Test samples for sti: 10\n",
      "Train samples for mnst: 111\n",
      "Validation samples for mnst: 10\n",
      "Test samples for mnst: 10\n",
      "Train samples for ads: 111\n",
      "Validation samples for ads: 10\n",
      "Test samples for ads: 10\n",
      "Train samples for dva: 111\n",
      "Validation samples for dva: 10\n",
      "Test samples for dva: 10\n",
      "Train samples for pep: 111\n",
      "Validation samples for pep: 10\n",
      "Test samples for pep: 10\n",
      "Train samples for wynn: 111\n",
      "Validation samples for wynn: 10\n",
      "Test samples for wynn: 10\n",
      "Train samples for mdlz: 111\n",
      "Validation samples for mdlz: 10\n",
      "Test samples for mdlz: 10\n",
      "Train samples for regn: 111\n",
      "Validation samples for regn: 10\n",
      "Test samples for regn: 10\n",
      "Train samples for incy: 111\n",
      "Validation samples for incy: 10\n",
      "Test samples for incy: 10\n",
      "Train samples for pnr: 111\n",
      "Validation samples for pnr: 10\n",
      "Test samples for pnr: 10\n",
      "Train samples for etr: 111\n",
      "Validation samples for etr: 10\n",
      "Test samples for etr: 10\n",
      "Train samples for tss: 111\n",
      "Validation samples for tss: 10\n",
      "Test samples for tss: 10\n",
      "Train samples for duk: 111\n",
      "Validation samples for duk: 10\n",
      "Test samples for duk: 10\n",
      "Train samples for mtb: 111\n",
      "Validation samples for mtb: 10\n",
      "Test samples for mtb: 10\n",
      "Train samples for ksu: 111\n",
      "Validation samples for ksu: 10\n",
      "Test samples for ksu: 10\n",
      "Train samples for fcx: 111\n",
      "Validation samples for fcx: 10\n",
      "Test samples for fcx: 10\n",
      "Train samples for aee: 111\n",
      "Validation samples for aee: 10\n",
      "Test samples for aee: 10\n",
      "Train samples for wfc: 111\n",
      "Validation samples for wfc: 10\n",
      "Test samples for wfc: 10\n",
      "Train samples for flir: 111\n",
      "Validation samples for flir: 10\n",
      "Test samples for flir: 10\n",
      "Train samples for sbac: 111\n",
      "Validation samples for sbac: 10\n",
      "Test samples for sbac: 10\n",
      "Train samples for vno: 111\n",
      "Validation samples for vno: 10\n",
      "Test samples for vno: 10\n",
      "Train samples for mat: 111\n",
      "Validation samples for mat: 10\n",
      "Test samples for mat: 10\n",
      "Train samples for zion: 111\n",
      "Validation samples for zion: 10\n",
      "Test samples for zion: 10\n",
      "Train samples for nwl: 111\n",
      "Validation samples for nwl: 10\n",
      "Test samples for nwl: 10\n",
      "Train samples for gd: 111\n",
      "Validation samples for gd: 10\n",
      "Test samples for gd: 10\n",
      "Train samples for amgn: 111\n",
      "Validation samples for amgn: 10\n",
      "Test samples for amgn: 10\n"
     ]
    }
   ],
   "source": [
    "window_length = 90\n",
    "BATCH_SIZE = int(window_length / 5)\n",
    "\n",
    "for i, (ticker, ds) in enumerate(stocks_data.items()):\n",
    "    x_train_dataset = ds['x_train_dataset']\n",
    "    y_train_dataset = ds['y_train_dataset']\n",
    "    \n",
    "    x_valid_dataset = ds['x_valid_dataset']\n",
    "    y_valid_dataset = ds['y_valid_dataset']\n",
    "    \n",
    "    x_test_dataset = ds['x_test_dataset']\n",
    "    y_test_dataset = ds['y_test_dataset']\n",
    "    \n",
    "    train_generator = TimeseriesGenerator(x_train_dataset, y_train_dataset, length=window_length, batch_size=BATCH_SIZE)\n",
    "    print('Train samples for {}: {}'.format(ticker, len(train_generator)))\n",
    "\n",
    "    valid_generator = TimeseriesGenerator(x_valid_dataset, y_valid_dataset, length=window_length, batch_size=BATCH_SIZE)\n",
    "    print('Validation samples for {}: {}'.format(ticker, len(valid_generator)))\n",
    "\n",
    "    test_generator = TimeseriesGenerator(x_test_dataset, y_test_dataset, length=window_length, batch_size=BATCH_SIZE)\n",
    "    print('Test samples for {}: {}'.format(ticker, len(test_generator)))\n",
    "    \n",
    "    ds['train_generator'] = train_generator\n",
    "    ds['valid_generator'] = valid_generator\n",
    "    ds['test_generator'] = test_generator\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating final dataframe for predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i, (ticker, ds) in enumerate(stocks_data.items()):\n",
    "    train_generator = ds['train_generator']\n",
    "    valid_generator = ds['valid_generator']\n",
    "    test_generator = ds['test_generator']\n",
    "    \n",
    "    x_scaler = ds['x_scaler']\n",
    "    y_scaler = ds['y_scaler']\n",
    "    \n",
    "    filepath='modelsneg/{}.weights.best.hdf5'.format(ticker)\n",
    "    OUTPUT_SIZE = 1\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(window_length, OUTPUT_SIZE * len(x_columns))))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(OUTPUT_SIZE))\n",
    "    \n",
    "    model.load_weights(filepath)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "#     val_loss = model.evaluate_generator(valid_generator)\n",
    "#     print('Val loss for {}: {}'.format(ticker, val_loss))\n",
    "    \n",
    "    # Make test predictions\n",
    "    test_predict = model.predict_generator(test_generator)\n",
    "    predicted_df = pd.DataFrame(y_scaler.inverse_transform(test_predict))\n",
    "    predicted_df = predicted_df.rename(columns={0: ticker})\n",
    "    \n",
    "    original_test = stocks_data[ticker]['y_test'].iloc[window_length:]\n",
    "    predicted_df.index = original_test.index\n",
    "    \n",
    "    if count > 0:\n",
    "        predicted_ticker = pd.concat([predicted_df[ticker], predicted_ticker], axis=1)\n",
    "    else: \n",
    "        predicted_ticker = predicted_df[ticker]\n",
    "        \n",
    "    count += 1\n",
    "        \n",
    "#     if count == 3: break\n",
    "#     %matplotlib inline\n",
    "#     plt.figure(figsize=(32, 20))\n",
    "\n",
    "#     plt.plot(predicted_ticker[ticker], linewidth=1, alpha=0.8)\n",
    "#     plt.plot(stocks_data[ticker]['y'], linewidth=1, alpha=0.8)\n",
    "#     plt.title('Plot for {}, val loss: {}'.format(ticker.upper(), val_loss))\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ticker.to_csv('predicted_adj_close_50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm result for msci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss for msci: 0.010379942593556879\n"
     ]
    }
   ],
   "source": [
    "ticker = 'msci'\n",
    "ds = stocks_data[ticker]\n",
    "\n",
    "train_generator = ds['train_generator']\n",
    "valid_generator = ds['valid_generator']\n",
    "test_generator = ds['test_generator']\n",
    "\n",
    "x_scaler = ds['x_scaler']\n",
    "y_scaler = ds['y_scaler']\n",
    "\n",
    "filepath='modelsneg/{}.weights.best.hdf5'.format(ticker)\n",
    "OUTPUT_SIZE = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(window_length, OUTPUT_SIZE * len(x_columns))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(OUTPUT_SIZE))\n",
    "\n",
    "model.load_weights(filepath)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "val_loss = model.evaluate_generator(valid_generator)\n",
    "print('Val loss for {}: {}'.format(ticker, val_loss))\n",
    "\n",
    "# Make test predictions\n",
    "test_predict = model.predict_generator(test_generator)\n",
    "predicted_df = pd.DataFrame(y_scaler.inverse_transform(test_predict))\n",
    "predicted_df = predicted_df.rename(columns={0: ticker})\n",
    "\n",
    "original_test = stocks_data[ticker]['y_test'].iloc[window_length:]\n",
    "predicted_df.index = original_test.index\n",
    "\n",
    "predicted_ticker = pd.concat([predicted_df[ticker], predicted_df[ticker]], axis=1)\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.figure(figsize=(32, 20))\n",
    "\n",
    "# plt.plot(predicted_ticker[ticker], linewidth=1, alpha=0.8)\n",
    "# plt.plot(stocks_data[ticker]['y'], linewidth=1, alpha=0.8)\n",
    "# plt.title('Plot for {}, val loss: {}'.format(ticker.upper(), val_loss))\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
